{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLAB = False\n",
    "\n",
    "metrics = ['accuracy', 'precision', 'recall', 'dice', 'iou', 'volumetric_similarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Copy your csv with splits \n",
    "    !cp ./drive/My\\ Drive/Code/CV/split.csv ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_PATH = '../results/'\n",
    "SPLIT_PATH = '../split/sample_split.csv'\n",
    "\n",
    "if COLAB:\n",
    "    RESULTS_PATH = './drive/My Drive/Code/CV/results/'\n",
    "    SPLIT_PATH = 'split.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "SPLITS = pd.read_csv(SPLIT_PATH).split.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>dice</th>\n",
       "      <th>examination</th>\n",
       "      <th>fn</th>\n",
       "      <th>fp</th>\n",
       "      <th>iou</th>\n",
       "      <th>precision</th>\n",
       "      <th>preds_volume</th>\n",
       "      <th>recall</th>\n",
       "      <th>split</th>\n",
       "      <th>tp</th>\n",
       "      <th>true_volume</th>\n",
       "      <th>volumetric_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999466</td>\n",
       "      <td>0.995206</td>\n",
       "      <td>P1B1</td>\n",
       "      <td>171</td>\n",
       "      <td>109</td>\n",
       "      <td>0.990458</td>\n",
       "      <td>0.996264</td>\n",
       "      <td>2901.708678</td>\n",
       "      <td>0.994151</td>\n",
       "      <td>0</td>\n",
       "      <td>29064</td>\n",
       "      <td>2907.875543</td>\n",
       "      <td>0.998939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999504</td>\n",
       "      <td>0.995157</td>\n",
       "      <td>P1B2</td>\n",
       "      <td>163</td>\n",
       "      <td>97</td>\n",
       "      <td>0.990361</td>\n",
       "      <td>0.996382</td>\n",
       "      <td>2666.870499</td>\n",
       "      <td>0.993936</td>\n",
       "      <td>0</td>\n",
       "      <td>26715</td>\n",
       "      <td>2673.435226</td>\n",
       "      <td>0.998771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy      dice examination   fn   fp       iou  precision  \\\n",
       "0  0.999466  0.995206        P1B1  171  109  0.990458   0.996264   \n",
       "1  0.999504  0.995157        P1B2  163   97  0.990361   0.996382   \n",
       "\n",
       "   preds_volume    recall  split     tp  true_volume  volumetric_similarity  \n",
       "0   2901.708678  0.994151      0  29064  2907.875543               0.998939  \n",
       "1   2666.870499  0.993936      0  26715  2673.435226               0.998771  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(RESULTS_PATH + '0_proper.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "postprocessed_means = []\n",
    "for split in range(SPLITS):\n",
    "    means.append(pd.read_csv(f'{RESULTS_PATH}{split}_proper.csv')[['split'] + metrics].mean())\n",
    "    postprocessed_means.append(pd.read_csv(f'{RESULTS_PATH}{split}_proper_postprocess.csv')[['split'] + metrics].mean())\n",
    "\n",
    "df = pd.DataFrame(means)\n",
    "postprocessed_df = pd.DataFrame(postprocessed_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>dice</th>\n",
       "      <th>iou</th>\n",
       "      <th>volumetric_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999485</td>\n",
       "      <td>0.996323</td>\n",
       "      <td>0.994043</td>\n",
       "      <td>0.995182</td>\n",
       "      <td>0.990410</td>\n",
       "      <td>0.998855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999466</td>\n",
       "      <td>0.996264</td>\n",
       "      <td>0.994151</td>\n",
       "      <td>0.995206</td>\n",
       "      <td>0.990458</td>\n",
       "      <td>0.998939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split  accuracy  precision    recall      dice       iou  \\\n",
       "0    0.0  0.999485   0.996323  0.994043  0.995182  0.990410   \n",
       "1    1.0  0.999466   0.996264  0.994151  0.995206  0.990458   \n",
       "\n",
       "   volumetric_similarity  \n",
       "0               0.998855  \n",
       "1               0.998939  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>dice</th>\n",
       "      <th>iou</th>\n",
       "      <th>volumetric_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999485</td>\n",
       "      <td>0.996323</td>\n",
       "      <td>0.994043</td>\n",
       "      <td>0.995182</td>\n",
       "      <td>0.990410</td>\n",
       "      <td>0.998855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999466</td>\n",
       "      <td>0.996264</td>\n",
       "      <td>0.994151</td>\n",
       "      <td>0.995206</td>\n",
       "      <td>0.990458</td>\n",
       "      <td>0.998939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split  accuracy  precision    recall      dice       iou  \\\n",
       "0    0.0  0.999485   0.996323  0.994043  0.995182  0.990410   \n",
       "1    1.0  0.999466   0.996264  0.994151  0.995206  0.990458   \n",
       "\n",
       "   volumetric_similarity  \n",
       "0               0.998855  \n",
       "1               0.998939  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postprocessed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9995 +/- 0.0000\n",
      "precision: 0.9963 +/- 0.0000\n",
      "recall: 0.9941 +/- 0.0001\n",
      "dice: 0.9952 +/- 0.0000\n",
      "iou: 0.9904 +/- 0.0000\n",
      "volumetric_similarity: 0.9989 +/- 0.0001\n"
     ]
    }
   ],
   "source": [
    "means, stds = df[metrics].mean(), df[metrics].std()\n",
    "for metric in metrics:\n",
    "    print(f'{metric}: {means[metric]:.4f} +/- {stds[metric]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9995 +/- 0.0000\n",
      "precision: 0.9963 +/- 0.0000\n",
      "recall: 0.9941 +/- 0.0001\n",
      "dice: 0.9952 +/- 0.0000\n",
      "iou: 0.9904 +/- 0.0000\n",
      "volumetric_similarity: 0.9989 +/- 0.0001\n"
     ]
    }
   ],
   "source": [
    "means, stds = postprocessed_df[metrics].mean(), postprocessed_df[metrics].std()\n",
    "for metric in metrics:\n",
    "    print(f'{metric}: {means[metric]:.4f} +/- {stds[metric]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9995 +/- 0.0000\n",
      "precision: 0.9957 +/- 0.0013\n",
      "recall: 0.9943 +/- 0.0004\n",
      "dice: 0.9950 +/- 0.0005\n",
      "iou: 0.9900 +/- 0.0009\n",
      "volumetric_similarity: 0.9990 +/- 0.0003\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{RESULTS_PATH}testset_proper.csv\")\n",
    "means, stds = df[metrics].mean(), df[metrics].std()\n",
    "for metric in metrics:\n",
    "    print(f'{metric}: {means[metric]:.4f} +/- {stds[metric]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9995 +/- 0.0000\n",
      "precision: 0.9957 +/- 0.0013\n",
      "recall: 0.9943 +/- 0.0004\n",
      "dice: 0.9950 +/- 0.0005\n",
      "iou: 0.9900 +/- 0.0009\n",
      "volumetric_similarity: 0.9990 +/- 0.0003\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{RESULTS_PATH}testset_proper_postprocess.csv\")\n",
    "means, stds = df[metrics].mean(), df[metrics].std()\n",
    "for metric in metrics:\n",
    "    print(f'{metric}: {means[metric]:.4f} +/- {stds[metric]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
