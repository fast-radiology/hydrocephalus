{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLAB = False\n",
    "\n",
    "metrics = ['accuracy', 'precision', 'recall', 'dice', 'iou', 'volumetric_similarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Copy your csv with splits \n",
    "    !cp ./drive/My\\ Drive/Code/CV/split.csv ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_PATH = '../results/'\n",
    "SPLIT_PATH = '../split/sample_split.csv'\n",
    "\n",
    "if COLAB:\n",
    "    RESULTS_PATH = './drive/My Drive/Code/CV/results/'\n",
    "    SPLIT_PATH = 'split.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "SPLITS = pd.read_csv(SPLIT_PATH).split.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>dice</th>\n",
       "      <th>examination</th>\n",
       "      <th>fn</th>\n",
       "      <th>fp</th>\n",
       "      <th>iou</th>\n",
       "      <th>precision</th>\n",
       "      <th>preds_volume</th>\n",
       "      <th>recall</th>\n",
       "      <th>split</th>\n",
       "      <th>tp</th>\n",
       "      <th>true_volume</th>\n",
       "      <th>volumetric_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999464</td>\n",
       "      <td>0.994270</td>\n",
       "      <td>P2B1</td>\n",
       "      <td>128</td>\n",
       "      <td>153</td>\n",
       "      <td>0.988605</td>\n",
       "      <td>0.993764</td>\n",
       "      <td>2440.188496</td>\n",
       "      <td>0.994777</td>\n",
       "      <td>0</td>\n",
       "      <td>24380</td>\n",
       "      <td>2437.701857</td>\n",
       "      <td>0.999490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999504</td>\n",
       "      <td>0.995157</td>\n",
       "      <td>P3B1</td>\n",
       "      <td>163</td>\n",
       "      <td>97</td>\n",
       "      <td>0.990361</td>\n",
       "      <td>0.996382</td>\n",
       "      <td>2666.870499</td>\n",
       "      <td>0.993936</td>\n",
       "      <td>0</td>\n",
       "      <td>26715</td>\n",
       "      <td>2673.435226</td>\n",
       "      <td>0.998771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy      dice examination   fn   fp       iou  precision  \\\n",
       "0  0.999464  0.994270        P2B1  128  153  0.988605   0.993764   \n",
       "1  0.999504  0.995157        P3B1  163   97  0.990361   0.996382   \n",
       "\n",
       "   preds_volume    recall  split     tp  true_volume  volumetric_similarity  \n",
       "0   2440.188496  0.994777      0  24380  2437.701857               0.999490  \n",
       "1   2666.870499  0.993936      0  26715  2673.435226               0.998771  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(RESULTS_PATH + '0_proper.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "postprocessed_means = []\n",
    "for split in range(SPLITS + 1):\n",
    "    means.append(pd.read_csv(f'{RESULTS_PATH}{split}_proper.csv')[['split'] + metrics].mean())\n",
    "    postprocessed_means.append(pd.read_csv(f'{RESULTS_PATH}{split}_proper_postprocess.csv')[['split'] + metrics].mean())\n",
    "\n",
    "df = pd.DataFrame(means)\n",
    "postprocessed_df = pd.DataFrame(postprocessed_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>dice</th>\n",
       "      <th>iou</th>\n",
       "      <th>volumetric_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999484</td>\n",
       "      <td>0.995073</td>\n",
       "      <td>0.994356</td>\n",
       "      <td>0.994714</td>\n",
       "      <td>0.989483</td>\n",
       "      <td>0.999130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999479</td>\n",
       "      <td>0.996303</td>\n",
       "      <td>0.994079</td>\n",
       "      <td>0.995190</td>\n",
       "      <td>0.990426</td>\n",
       "      <td>0.998883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split  accuracy  precision    recall      dice       iou  \\\n",
       "0    0.0  0.999484   0.995073  0.994356  0.994714  0.989483   \n",
       "1    1.0  0.999479   0.996303  0.994079  0.995190  0.990426   \n",
       "\n",
       "   volumetric_similarity  \n",
       "0               0.999130  \n",
       "1               0.998883  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>dice</th>\n",
       "      <th>iou</th>\n",
       "      <th>volumetric_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999484</td>\n",
       "      <td>0.995073</td>\n",
       "      <td>0.994356</td>\n",
       "      <td>0.994714</td>\n",
       "      <td>0.989483</td>\n",
       "      <td>0.999130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999479</td>\n",
       "      <td>0.996303</td>\n",
       "      <td>0.994079</td>\n",
       "      <td>0.995190</td>\n",
       "      <td>0.990426</td>\n",
       "      <td>0.998883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split  accuracy  precision    recall      dice       iou  \\\n",
       "0    0.0  0.999484   0.995073  0.994356  0.994714  0.989483   \n",
       "1    1.0  0.999479   0.996303  0.994079  0.995190  0.990426   \n",
       "\n",
       "   volumetric_similarity  \n",
       "0               0.999130  \n",
       "1               0.998883  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postprocessed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9995 +/- 0.0000\n",
      "precision: 0.9957 +/- 0.0009\n",
      "recall: 0.9942 +/- 0.0002\n",
      "dice: 0.9950 +/- 0.0003\n",
      "iou: 0.9900 +/- 0.0007\n",
      "volumetric_similarity: 0.9990 +/- 0.0002\n"
     ]
    }
   ],
   "source": [
    "means, stds = df[metrics].mean(), df[metrics].std()\n",
    "for metric in metrics:\n",
    "    print(f'{metric}: {means[metric]:.4f} +/- {stds[metric]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9995 +/- 0.0000\n",
      "precision: 0.9957 +/- 0.0009\n",
      "recall: 0.9942 +/- 0.0002\n",
      "dice: 0.9950 +/- 0.0003\n",
      "iou: 0.9900 +/- 0.0007\n",
      "volumetric_similarity: 0.9990 +/- 0.0002\n"
     ]
    }
   ],
   "source": [
    "means, stds = postprocessed_df[metrics].mean(), postprocessed_df[metrics].std()\n",
    "for metric in metrics:\n",
    "    print(f'{metric}: {means[metric]:.4f} +/- {stds[metric]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9995 +/- 0.0000\n",
      "precision: 0.9958 +/- 0.0011\n",
      "recall: 0.9942 +/- 0.0003\n",
      "dice: 0.9950 +/- 0.0004\n",
      "iou: 0.9900 +/- 0.0008\n",
      "volumetric_similarity: 0.9990 +/- 0.0003\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{RESULTS_PATH}testset_proper.csv\")\n",
    "means, stds = df[metrics].mean(), df[metrics].std()\n",
    "for metric in metrics:\n",
    "    print(f'{metric}: {means[metric]:.4f} +/- {stds[metric]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9995 +/- 0.0000\n",
      "precision: 0.9958 +/- 0.0011\n",
      "recall: 0.9942 +/- 0.0003\n",
      "dice: 0.9950 +/- 0.0004\n",
      "iou: 0.9900 +/- 0.0008\n",
      "volumetric_similarity: 0.9990 +/- 0.0003\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{RESULTS_PATH}testset_proper_postprocess.csv\")\n",
    "means, stds = df[metrics].mean(), df[metrics].std()\n",
    "for metric in metrics:\n",
    "    print(f'{metric}: {means[metric]:.4f} +/- {stds[metric]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
